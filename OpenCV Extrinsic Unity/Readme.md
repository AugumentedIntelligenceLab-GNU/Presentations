# OpenCV Extrinsic Unity 연구 계획서

OpenCV로 추출한 마커의 외부파라미터를 이용하여 Unity 3D 공간에 정확하게 띄우는 방법

## 목차

1. 초록
2. 연구 목적
3. 연구의 중요성
4. 연구의 제한점
5. 상황
6. 행동의 초점
7. 기록
8. 연구 일정
9. 자료 수집
10. 자료 분석
11. 예상되는 최종 결과
12. 윤리적 고려
13. 참고 문헌

## 연구 목적

- 외부 파라미터로 3D 공간에 띄우기

- 기존의 여러 센서로 3D 공간을 스캔했는데, 카메라만으로 하자!
  
  - 애플의 비싼 MR 비전 프로. 접근성 떨어짐
  - 카메라만으로 3D 스캔하자 (SLAM - Vuforia ?)

- OpenCV로 추출한 외부파라미터를 이용해보자?

## 연구 방법

손 으로하는증강현실은뭐든지잘해 프로젝트에서 응용

> - $[R|t] _{H2C} ⊙ [mp]h = [P]C1$
>   
>   - Hand의 공간좌표 구현.
>   - [R|t]h2c에 [P]h(손의 좌표) 곱하면 [p]c(카메라 상의 좌표) 나옴
> 
> - ${[R|t]*{W2C}} ^{-1} = [R|t]*{C2W}$
>   
>   - 3D 공간에 물체 구현.
>   - [R|t]w2c의 역함수 [R|t]c2w 구함.
> 
> - $[R|t]_{C2W} ⊙ [P]C1 = [P]W$
>   
>   - 물체의 카메라 상의 좌표 곱하면 [P]w(현실의 좌표) 나옴.
> 
> - $[R|t]_{W2C} ⊙ [P]W = [P]C2$
>   
>   - [P]C1 과 [P]C2 는 같은가?
>   - 이론 상 같을 것이다.
>   - 2개가 같으면 증강현실 구현 완료
> 
> - 미디어파이프로 바로 구할 수 있는 [P]C1 과 위 과정을 거쳐 나온 [P]C2를 동시에 출력하기

1. 마커의 공간좌표 구하기
   
   1. OpenCV 마커의 외부파라미터 구하기
   2. SolvePnP로 tvec, rvec 구함

2. rvec, tvec를 이용하여 유니티 3D 공간에 똑같이 구현?
   
   1. test.cs?

3. 구현한 3D 공간에 물체 띄우기



### 생각할 점

- Unity에서 rvec, tvec를 구할 수 있나?
  
  - ~~OpenCV에서 벡터 구해서 파일 export, Unity에서 Import~~
    
    - 속도 느릴 듯
  
  - ~~Asset: AR Foundation package, Vuforia SDK, or OpenCV for Unity asset~~
    
    - 연구 목표: Vuforia 등 쓰지 않는 것.
  
  - [opencvsharp](https://github.com/shimat/opencvsharp)
  
  - dll 파일 직접 만들기: [유니티에서 OpenCV 사용하기 - 3.실전(이미지 전달,통신)](https://darkstart.tistory.com/42?category=840167)

## 연구의 중요성

- 애플 MR 헤드셋 비전 프로 ㅈㄴ 비쌈

- 카드보드 급 대중성있는 MR 기기 필요
  
  - 스마트폰 카메라 하나만으로 3D 공간 구현 

- 이를 통해 MR의 접근성, 대중성 향상

## 연구의 제한점

- 센서 없이

## 이론적 배경 및 선행연구 고찰

- 기술
  
  - LiDar
  
  - 초음파
  
  - SLAM - Vuforia

- 논문
  
  - 유니티를 활용한 외부 파라미터 교정 시뮬레이터 구현
